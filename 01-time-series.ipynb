{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "source": [
    "<div><img style=\"float: left; padding-right: 3em;\" src=\"https://avatars.githubusercontent.com/u/19476722\" width=\"150\" /><div/>\n",
    "\n",
    "# Earth Data Science Coding Challenge!\n",
    "Before we get started, make sure to read or review the guidelines below. These will help make sure that your code is **readable** and **reproducible**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "source": [
    "## Don't get **caught** by these Jupyter notebook gotchas\n",
    "\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:4800/format:webp/1*o0HleR7BSe8W-pTnmucqHA.jpeg\" width=300 style=\"padding: 1em; border-style: solid; border-color: grey;\" />\n",
    "\n",
    "  > *Image source: https://alaskausfws.medium.com/whats-big-and-brown-and-loves-salmon-e1803579ee36*\n",
    "\n",
    "These are the most common issues that will keep you from getting started and delay your code review:\n",
    "\n",
    "1. When you try to run some code on GitHub Codespaces, you may be prompted to select a **kernel**.\n",
    "   * The **kernel** refers to the version of Python you are using\n",
    "   * You should use the **base** kernel, which should be the default option. \n",
    "   * You can also use the `Select Kernel` menu in the upper right to select the **base** kernel\n",
    "2. Before you commit your work, make sure it runs **reproducibly** by clicking:\n",
    "   1. `Restart` (this button won't appear until you've run some code), then\n",
    "   2. `Run All`\n",
    "\n",
    "## Check your code to make sure it's clean and easy to read\n",
    "\n",
    "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSO1w9WrbwbuMLN14IezH-iq2HEGwO3JDvmo5Y_hQIy7k-Xo2gZH-mP2GUIG6RFWL04X1k&usqp=CAU\" height=200 />\n",
    "\n",
    "* Format all cells prior to submitting (right click on your code).\n",
    "* Use expressive names for variables so you or the reader knows what they are. \n",
    "* Use comments to explain your code -- e.g. \n",
    "  ```python\n",
    "  # This is a comment, it starts with a hash sign\n",
    "  ```\n",
    "\n",
    "## Label and describe your plots\n",
    "\n",
    "![Source: https://xkcd.com/833](https://imgs.xkcd.com/comics/convincing.png)\n",
    "\n",
    "Make sure each plot has:\n",
    "  * A title that explains where and when the data are from\n",
    "  * x- and y- axis labels with **units** where appropriate\n",
    "  * A legend where appropriate\n",
    "\n",
    "\n",
    "## Icons: how to use this notebook\n",
    "We use the following icons to let you know when you need to change something to complete the challenge:\n",
    "  * &#128187; means you need to write or edit some code.\n",
    "  \n",
    "  * &#128214;  indicates recommended reading\n",
    "  \n",
    "  * &#9998; marks written responses to questions\n",
    "  \n",
    "  * &#127798; is an optional extra challenge\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "hideCode": false,
    "hidePrompt": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "60ea5b3a910b97ebea86e6ed784e7756",
     "grade": false,
     "grade_id": "instr-headline",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# In  2019 there were floods across the Midwestern US\n",
    "![Inland floods in the Midwest - houses partially submerged in brown water](https://nationalfloodservices.com/wp-content/uploads/2020/09/midwest-flood-blog-1.png)\n",
    "\n",
    "> Image source: <a src=https://nationalfloodservices.com/blog/the-2019-midwestern-floods-the-insidious-damage-of-inland-flooding/> National Flood Services - The 2019 Midwestern Floods</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aeecc900129dc886aabe93e84546db1f",
     "grade": false,
     "grade_id": "instr-intro",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "From March to December 2019, large parts of the midwestern U.S. were flooded. What happened to cause this flooding? What impacts did the flooding have? Before we look at data about the flooding, we need to check out what other sources are saying about it.\n",
    "\n",
    "&#128214; Here are some resources from different sources to get you started:\n",
    "  * [The New York Times](https://www.nytimes.com/interactive/2019/09/11/us/midwest-flooding.html)\n",
    "  * [National Flood Services](https://nationalfloodservices.com/blog/the-2019-midwestern-floods-the-insidious-damage-of-inland-flooding/)\n",
    "\n",
    "&#128172; If you or someone you know have experience with this site, or \n",
    "were there during the floods, we also invite you to write about that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c4d9c4e6ce71e41b8bcf00169b59f047",
     "grade": false,
     "grade_id": "step-0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## STEP 1: Set up Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "40cb2299bd6ddcf72a02f82bf9d79762",
     "grade": false,
     "grade_id": "instr-set-up",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Use the cell below to add necessary **package imports** to this notebook. It's best to import everything in your very first code cell because it helps folks who are reading your code to figure out where everything comes from (mostly right now this is **you** in the future). It's *very* frustrating to try to figure out what packages need to be installed to get some code to run.\n",
    "\n",
    "&#128214; Our friend [the PEP-8 style guide has some things to say about imports](https://peps.python.org/pep-0008/#imports). In particular - **standard library packages** should be listed at the top. These are packages that you don't need to install because they come with Python. You can check if a package is part of the standard library by searching the [Python Standard Library documentation page](https://docs.python.org/3/library/). \n",
    "\n",
    "&#128187; Your task:\n",
    "  * **Uncomment** all the import lines below. HINT: Use the `CMD`-`/` shortcut to uncomment many lines at once.\n",
    "  * Add the **library for working with DataFrames in Python** to the imports, as well as the **hvplot extension**\n",
    "  * Separate the **standard library package(s)** at the top\n",
    "  * Run and test your import cell to make sure everything will work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e27a056e6b2b8688efbbcf00a4ecc9d",
     "grade": false,
     "grade_id": "student-imports-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# import folium\n",
    "# from io import BytesIO\n",
    "# import requests\n",
    "# import subprocess\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "hideCode": false,
    "hidePrompt": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06cb0e2577dcad77607c9777b36a9417",
     "grade": true,
     "grade_id": "student-imports-tests",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# RUN THIS CELL TO TEST YOUR CODE - DO NOT MODIFY!\n",
    "import_pts = 0\n",
    "\n",
    "# Check that pandas has been imported properly\n",
    "try:\n",
    "    pd.DataFrame()\n",
    "    import_pts += 1\n",
    "    print('\\u2705 Great work! '\n",
    "          'You correctly imported the pandas library.')\n",
    "except:\n",
    "    print('\\u274C Oops - pandas was not imported correctly.')\n",
    "    \n",
    "# Check that hvplot has been imported\n",
    "try:\n",
    "    pd.DataFrame().hvplot\n",
    "    import_pts += 1\n",
    "    print('\\u2705 Great work! '\n",
    "          'You correctly imported the hvplot.pandas library.')\n",
    "except:\n",
    "    print('\\u274C Oops - hvplot.pandas was not imported correctly.')\n",
    "\n",
    "# Subtract one point for any PEP-8 errors\n",
    "tmp_path = \"tmp.py\"\n",
    "with open(tmp_path, \"w\") as tmp_file:\n",
    "    tmp_file.write(In[-2])\n",
    "ignore_flake8 = 'W292,F401,E302'\n",
    "flake8_out = subprocess.run(\n",
    "    ['flake8', \n",
    "     '--ignore', ignore_flake8, \n",
    "     '--import-order-style', 'edited',\n",
    "     '--count', \n",
    "     tmp_path],\n",
    "    stdout=subprocess.PIPE,\n",
    ").stdout.decode(\"ascii\")\n",
    "print(flake8_out)\n",
    "import_pts -= int(flake8_out.splitlines()[-1])\n",
    "\n",
    "print(\n",
    "    \"\\n \\u27A1 You received {} out of 2 points.\".format(import_pts)\n",
    ")\n",
    "\n",
    "import_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "59e76c599e03aace392eb8618c8ebbbc",
     "grade": false,
     "grade_id": "step-1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## STEP 2: SITE MAP AND DESCRIPTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "565dbff56eb34d997bab2d1d9af01c60",
     "grade": false,
     "grade_id": "task-site",
     "locked": true,
     "points": 8,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "\n",
    "### Near Omaha, NE, roads were flooded and levees overflowed\n",
    "\n",
    "![The Platte and Missouri rivers overflow their banks. Before and after images show a large extent of land outside the usual riverbanks flooded.](https://nationalfloodservices.com/wp-content/uploads/2020/09/Historic_floods_have_inundated_Nebraska_40463013783.jpg)\n",
    "\n",
    "> Image Source: [National Flood Services](https://nationalfloodservices.com/blog/the-2019-midwestern-floods-the-insidious-damage-of-inland-flooding/)\n",
    "\n",
    "To start, you'll be focusing on the Missouri River at Omaha, a few miles north of where this image above depicts the junctions of the Platte and Missouri Rivers. Then, you'll pick your own site that was affected by a flood.\n",
    "\n",
    "### Site Description\n",
    "\n",
    "&#9998; In the cell below, describe the Omaha area and/or the Missouri River in a few sentences. \n",
    "You can include:\n",
    "  * Information about the **climatology** of the area, or typical \n",
    "  precipitation and temperature at different months of the year\n",
    "  * You don't need to include a **runoff ratio** (average annual runoff divided by average annual precipitation) for a river this large, since it would be hard to find and not as meaningful. If you are working with small watersheds you should definitely report this number. Check out the [GAGES II dataset](https://water.usgs.gov/GIS/dsdl/basinchar_and_report_sept_2011.zip)\n",
    "  * Which **wildlife and ecosystems** exist in the area\n",
    "  * What **communities and infrastructure** are in the area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WRITE YOUR SITE DESCRIPTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "116edb331ea993ba534a934f9afbe609",
     "grade": false,
     "grade_id": "task-map",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Site Map: The Missouri River near Omaha\n",
    "\n",
    "The code below will create an interactive map of the area using the **folium**\n",
    "library. But something is wrong - no one defined the names latitude and longitude.\n",
    "\n",
    "&#128187; Your task:\n",
    "  * Find the location of the Missouri River near Omaha **USGS stream gauge** using the [National Water Information System](https://waterdata.usgs.gov/nwis?). This is not the easiest thing to find if you aren't used to NWIS, so you can use the following instructions to get started:\n",
    "      * Go to the [National Water Information System Mapper](https://dashboard.waterdata.usgs.gov/app/nwd/en/)\n",
    "      * Type in `Omaha` in the `Find a Place` box and pick the one in Nebraska (NE)\n",
    "      * Click on the Missouri River near Omaha site. It should open a new window.\n",
    "      * Click on `Site page` at the top.\n",
    "      * Scroll to the bottom and open the `Location metadata` section. There you will find the latitude and longitude as decimal values.\n",
    "  * Define latitude and longitude variables to **match the variable names \n",
    "    used in the code**.\n",
    "  * Change the current label, \"Thingy\" to be descriptive of the site.\n",
    "  * Run and test your cell to make sure everything works.\n",
    "\n",
    "&#127798; EXTRA CHALLENGE: Customize your folium plot [using the folium documentation](https://python-visualization.github.io/folium/quickstart.html#Getting-Started). For example, you could:\n",
    "  * Change the base map images\n",
    "  * Change the initial zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a675b5d94d456541f785078a0459e4fd",
     "grade": false,
     "grade_id": "ans-map",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Initialize map and tweak settings\n",
    "m = folium.Map(\n",
    "    # Location to display\n",
    "    location=(sg_lat, sg_lon),\n",
    "    # Turns off annoying zooming while trying to scroll to the next cell\n",
    "    scrollWheelZoom=False)\n",
    "\n",
    "# Put a marker at the stream gauge location\n",
    "folium.Marker([sg_lat, sg_lon], popup=\"Thingy\").add_to(m)\n",
    "\n",
    "# Display the map\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9afe82784a25185dc4d74ec532160aa3",
     "grade": false,
     "grade_id": "step-2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## STEP 3: DOWNLOAD TIME SERIES DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "371044e37d2fedc9de319c435ab0ccf9",
     "grade": false,
     "grade_id": "instr-floods",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### One way to express how big a flood is by estimating how often larger floods occur.\n",
    "\n",
    "For example, you might have heard news media talking about a \"100-year flood\". \n",
    "\n",
    "Next, you will write Python code to download and work with a **time series** of streamflow data during the flooding on the Missouri River.\n",
    "\n",
    "> A **time series** of data is taken at the same location but collected regularly or semi-regularly over time. \n",
    "\n",
    "You will then consider how the values compared to previous years before the flood event by computing the flood's **return period**.\n",
    "\n",
    "> A **return period** is an estimate of how often you might expect to see a flood of at least a particular size. This does *NOT* mean an extreme flood \"has\" to occur within the return period, or that it couldn't occur more than once.\n",
    "\n",
    "&#128214; Here are some resources from your textbook you can review to learn more:\n",
    "  * [Introduction to time-series data](https://www.earthdatascience.org/courses/use-data-open-source-python/use-time-series-data-in-python/)\n",
    "  * [Flood return period and probability](https://www.earthdatascience.org/courses/use-data-open-source-python/use-time-series-data-in-python/floods-return-period-and-probability/)\n",
    "\n",
    "&#9998; In the cell below, explain what data you will need to complete this analysis, including:\n",
    "  1. What type or types of data do you need?\n",
    "  2. How many years of data do you think you need to compute the return period of an extreme event like the 2019 Omaha floods?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "92d9fd524794a00722ea1d21f1ec9c7e",
     "grade": false,
     "grade_id": "task-url",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### US streamflow data are available from the National Water Information Service (NWIS) \n",
    "\n",
    "&#128187; Practice downloading the data you need using the NWIS website. **You will not use your downloaded data in the analysis, but you must follow these steps to get the correct urls.** In the cell below, use the following instructions to get urls for downloading the USGS data:\n",
    "\n",
    "1. Go back to the Missouri River near Omaha station page.\n",
    "2. This time, click `Data` instead of `Site Page`\n",
    "3. Select `Daily Data` from the list of datasets.\n",
    "4. Select the date range from October 1, 1991 to September 30, 2022, set your results to be as `Tab-separated`, and press `Go`.\n",
    "    > NOTE: For hydrologic data, we often use the **Water Year**, which starts the  October before in order to capture the full snow season. In this case, we are downloading WY1992-WY2022\n",
    "5. Copy the url that populates in your browser window and paste it below. You don't need to save the data - we will do that using Python.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9998; USGS streamflow URL: *url here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "977529b9aac562879d4c317ac13cd42b",
     "grade": false,
     "grade_id": "task-api",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "#### Exploring the NWIS API\n",
    "\n",
    "One way to access data is through an **Application Programming Interface**, or **API**. The URL you've just found is an example of a simple, public API. All the parameters of your data search are visible in the URL. For example, to get data starting in 2015, we could change `begin_date=1991-10-01` to `begin_date=2015-01-01`)\n",
    "\n",
    " &#9998; In the cell below - what parameter would you change in the USGS url if you wanted to switch locations?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WRITE YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aee8e586efb6a857d10616690c3fa2a2",
     "grade": false,
     "grade_id": "task-citation",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Data description and citation\n",
    "\n",
    "&#9998; In the cell below, describe your data. Include the following information:\n",
    "  1. A 1-2 sentence description of the data\n",
    "  2. Data citation\n",
    "  3. What are the units?\n",
    "  4. What is the time interval for each data point?\n",
    "  5. Is there a \"no data\" value, or a value used to indicate when the sensor was broken or didn't detect anything? (These are also known as NA, N/A, NaN, nan, or nodata values)\n",
    "\n",
    "&#128214; The [NWIS data format page](https://waterdata.usgs.gov/nwis/?tab_delimited_format_info) might be helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WRITE YOUR DATA DESCRIPTION AND CITATION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "hideCode": false,
    "hidePrompt": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "40bb2ef272c896c294bc599a75f11381",
     "grade": false,
     "grade_id": "set-working-directory-instructions",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Download the data\n",
    "\n",
    "In the cell below complete the following task:\n",
    "\n",
    "1. Use [the code suggested by ChatGPT for how to request a URL over HyperText Transfer Protocol (HTTP) in Python](https://chat.openai.com/share/ca03fcfd-1264-41a1-a19e-05dd57a842ce) as a starting point for your code.\n",
    "2. Replace the url in the code below with the USGS NWIS URL you found, and change the variable names to something descriptive.\n",
    "   > HINT: URLs are a type of Python object called a `string`. Make sure you put quotes around your URL so that Python knows how to interpret it!\n",
    "3. Call the response object at the end of the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "hideCode": false,
    "hidePrompt": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63910669445a1f9ab3d48ebaf370ef73",
     "grade": false,
     "grade_id": "download-and-set-working-directory",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c3fdd42732d7a48ac352ea46ea5b3a1a",
     "grade": true,
     "grade_id": "test-download",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ans_req = _\n",
    "req_pts = 0\n",
    "\n",
    "if ans_req.ok:\n",
    "    print('\\u2705 Great work! Your download succeeded')\n",
    "    req_pts += 4\n",
    "else:\n",
    "    print('\\u274C Hmm, looks like your url is not correct')\n",
    "    \n",
    "# Subtract one point for any PEP-8 errors\n",
    "tmp_path = \"tmp.py\"\n",
    "with open(tmp_path, \"w\") as tmp_file:\n",
    "    tmp_file.write(In[-2])\n",
    "ignore_flake8 = 'W292,F401,E302,F821'\n",
    "flake8_out = subprocess.run(\n",
    "    ['flake8', \n",
    "     '--ignore', ignore_flake8, \n",
    "     '--import-order-style', 'edited',\n",
    "     '--count', \n",
    "     tmp_path],\n",
    "    stdout=subprocess.PIPE,\n",
    ").stdout.decode(\"ascii\")\n",
    "print(flake8_out)\n",
    "req_pts -= int(flake8_out.splitlines()[-1])\n",
    "\n",
    "print('\\u27A1 You earned {} of 4 points for downloading data'.format(req_pts))\n",
    "\n",
    "req_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f01508a52a7c57d9e42bfba9aa4581ea",
     "grade": false,
     "grade_id": "step-3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## STEP 4: CLEAN UP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "61d6ebb94dd074a47489a5fbcb61946b",
     "grade": false,
     "grade_id": "instr-look-at-data",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### You will need to take a look at the raw downloaded data to figure out what import parameters to use with the pandas read_csv() function\n",
    "\n",
    "&#128187; In the cell below, replace `response` with the name of the response variable that you defined above.\n",
    "\n",
    "The code below prints the first 10 lines of your download and numbers them. Does this look like streamflow data to you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the top of the data\n",
    "for i, line in enumerate(nwis_response.content.splitlines()[:10]):\n",
    "    print(i, line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "91818f0cb841ee907383b85ab86fb4bc",
     "grade": false,
     "grade_id": "instr-comment",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the [NWIS documentation](https://waterdata.usgs.gov/nwis/?tab_delimited_format_info), they say that you can ignore lines that start with a hash sign (#) because they are **commented**. When we use pandas to import the data, we'll be able to tell it what character indicates a comment, but we're not there yet. The code below again prints the first 35 lines of the response content, this time skipping all commented lines. \n",
    "\n",
    "&#128187; In the cell below, replace `response` with the name of the response variable that you defined above. Then run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the data. What got downloaded?\n",
    "for i, line in enumerate(nwis_response.content.splitlines()[:35]):\n",
    "    # Skip commented lines\n",
    "    if not line.startswith(b'#'):\n",
    "        print(i, line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5511456e9ebcb95423d212ccb7d64d1e",
     "grade": false,
     "grade_id": "instr-describe-data",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "&#9998; What do you notice about the data now? In the following cell, write down your thoughts on:\n",
    "  * What separator or **delimiter** does the data use to separate columns?\n",
    "  * What should the data types of each column be?\n",
    "  * Which column contains the streamflow data?\n",
    "  * Do you need to skip any rows that don't contain data?\n",
    "  * Which column do you think makes sense as the **index** (unique identifier) for each row?\n",
    "  * Is there anything else strange?\n",
    "\n",
    "The answers to the questions above will help you figure out what parameters to use with the `pd.read_csv()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WRITE YOUR OBSERVATIONS ABOUT THE UNCLEANED DATA HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3262fb89d3a0988f875044f85cd3f2c6",
     "grade": false,
     "grade_id": "instr-import",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Now we're ready to import the data with pandas. \n",
    "\n",
    "Notice that when you print your downloaded data, each line has a `b` in front of it. The `b` stands for \"bytes\". In order for pandas to be able to read the data, we need to **decode** it so each line is a regular string. In the cell below, we do this using the `io.BytesIO` function, which tricks `pandas` into thinking it is reading a binary file.\n",
    "\n",
    "&#128187; Your task:\n",
    "\n",
    "Paste the following code in the cell below:\n",
    "```python\n",
    "pd.read_csv(\n",
    "    BytesIO(nwis_response.content),\n",
    "    # comment='',\n",
    "    # delimiter='', \n",
    "    # skiprows=[],\n",
    "    # names=[],\n",
    "    # index_col='',\n",
    "    # parse_dates=True,\n",
    ")\n",
    "```\n",
    "\n",
    "Then:\n",
    "  1. Replace `response` with the name of your HTTP Response variable\n",
    "  2. Uncomment the code below, **one line at a time**, running the code and making corrections in-between.\n",
    "  3. Using the observations you made above, add the necessary values to get `pandas` to correctly import the data.\n",
    "  4. Make sure to include units in your column names where applicable! What units are these streamflow measurements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f877ce12e05fcb22ab76b793ec817d4",
     "grade": false,
     "grade_id": "ans-import",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "094f2effb7c481e262e5a36586623ae5",
     "grade": true,
     "grade_id": "test-import",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ans_q = _\n",
    "q_points = 0\n",
    "\n",
    "if isinstance(ans_q, pd.DataFrame):\n",
    "    print(\"\\u2705 Great, you created a pandas dataframe above\")\n",
    "    q_points += 1\n",
    "else:\n",
    "    print(\"\\u274C Oops - the cell above should have a DataFrame output.\")\n",
    "\n",
    "if type(ans_q.index) == pd.DatetimeIndex:\n",
    "    print(\"\\u2705 Your DataFrame has the date as the index, \"\n",
    "          \"good job!\")\n",
    "    q_points += 2\n",
    "else:\n",
    "    print(\"\\u274C Your DataFrame does not have the date \"\n",
    "          \"as the index.\")\n",
    "\n",
    "if len(ans_q) == 11323:\n",
    "    print(\"\\u2705 Your DataFrame is the right length!\")\n",
    "    q_points += 2\n",
    "else:\n",
    "    print(\"\\u274C Check your date range.\")\n",
    "    \n",
    "if round(ans_q.iloc[:,2].mean(), 0)==38402.0:\n",
    "    print(\"\\u2705 Your streamflow DataFrame has the expected values \"\n",
    "          \"in it, good job!\")\n",
    "    q_points += 2\n",
    "else:\n",
    "    print(\"\\u274C Your streamflow DataFrame does not have the \"\n",
    "          \"expected values in it.\")\n",
    "\n",
    "# Subtract one point for any PEP-8 errors\n",
    "tmp_path = \"tmp.py\"\n",
    "with open(tmp_path, \"w\") as tmp_file:\n",
    "    tmp_file.write(In[-2])\n",
    "ignore_flake8 = 'W292,F401,E302,F821'\n",
    "flake8_out = subprocess.run(\n",
    "    ['flake8', \n",
    "     '--ignore', ignore_flake8, \n",
    "     '--import-order-style', 'edited',\n",
    "     '--count', \n",
    "     tmp_path],\n",
    "    stdout=subprocess.PIPE,\n",
    ").stdout.decode(\"ascii\")\n",
    "print(flake8_out)\n",
    "q_points -= int(flake8_out.splitlines()[-1])\n",
    "\n",
    "print(\"\\u27A1 You received {} out of 7 points for opening the \"\n",
    "      \"streamflow data.\".format(\n",
    "    q_points))\n",
    "q_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "617086bc7f7c06fd9aafd66587d7000e",
     "grade": false,
     "grade_id": "instr-type",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's check your data. A useful method for looking at the **datatypes** in your `pd.DataFrame` is the `pd.DataFrame.info()` method.\n",
    "\n",
    "> In Python, you will see both **methods** and **functions**. This is an *important and tricky* distinction we'll be talking about a lot. For right now -- functions have all of their arguments/parameters **inside** the parentheses, as in `pd.read_csv(args)`. For **methods**, the first argument is always some kind of Python **object** like a `pd.DataFrame`. Take a look at the next cell for an example of using the `pd.DataFrame.info()` **method**.\n",
    "\n",
    "\n",
    "&#128187;  Replace `dataframe` with the name of your DataFrame variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 5: PLOT THE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f93ae46734bf198adfc03c1937fba4c8",
     "grade": false,
     "grade_id": "instr-float",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Oops, we have one more problem! Take a look at the data types of your DataFrame columns...\n",
    "\n",
    "âœŽ In the cell below, write down what data type you would expect the streamflow column to be. The main options are: Integer, Float, Datetime, or Object.\n",
    "\n",
    "ðŸ“– Check out [this example showing the most common data types for pandas columns](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dtypes.html)\n",
    "\n",
    "> A **float** is a non-integer number. You can identify them because they have decimal points in Python, unlike integers. We do not call them decimals for a reason - a decimal.Decimal is different, and more precise than, a float in Python. If you are ever working with really, really small numbers, you may need to use decimals, but for most applications floats are fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3aa0edd6dc1ba49fb77a3f1c784b8e99",
     "grade": false,
     "grade_id": "discharge-subset-instructions",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Can we see the flood in the streamflow data?\n",
    "\n",
    "In the cell below, subset the stream discharge data to the same timeframe that you are interested in: February - April, 2019. Save the result to a variable and call it at the end of the cell for testing.\n",
    "\n",
    "You can find some [examples of subsetting time series data in the textbook](https://www.earthdatascience.org/courses/use-data-open-source-python/use-time-series-data-in-python/date-time-types-in-pandas-python/subset-time-series-data-python/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89f9f8ea1c69bde63c116ab0a6f1318c",
     "grade": false,
     "grade_id": "discharge-daily",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3a70577af5ffb7f5934c3aed86e7f84b",
     "grade": true,
     "grade_id": "cell-9ac99569c9bebaa3",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ans_subset = _\n",
    "subset_points = 0\n",
    "\n",
    "# Answer should be a DataFrame\n",
    "if isinstance(ans_subset, pd.DataFrame):\n",
    "    print(\"\\u2705 Great, you created a pandas dataframe above\")\n",
    "    subset_points += 1\n",
    "else:\n",
    "    print(\"\\u274C Oops - the cell above should have a DataFrame output.\")\n",
    "\n",
    "# Answer should include 731 days of data\n",
    "if len(ans_subset)==731:\n",
    "    print(\"\\u2705 Your DataFrame has the right number of days\")\n",
    "    subset_points += 2\n",
    "elif len(ans_subset) >731:\n",
    "    print(\"\\u274C Your subset has too many days.\")\n",
    "else:\n",
    "    print(\"\\u274C Your subset has too few days.\")\n",
    "\n",
    "# The mean of the streamflow column should be 1951\n",
    "if round(ans_subset.iloc[:,2].mean(), 0)==67960.0:\n",
    "    print(\"\\u2705 Your streamflow DataFrame has the expected values \"\n",
    "          \"in it, good job!\")\n",
    "    subset_points += 2\n",
    "else:\n",
    "    print(\"\\u274C Your streamflow DataFrame does not have the \"\n",
    "          \"expected values in it.\")\n",
    "\n",
    "# Subtract one point for any PEP-8 errors\n",
    "tmp_path = \"tmp.py\"\n",
    "with open(tmp_path, \"w\") as tmp_file:\n",
    "    tmp_file.write(In[-2])\n",
    "ignore_flake8 = 'W292,F401,E302,F821'\n",
    "flake8_out = subprocess.run(\n",
    "    ['flake8', \n",
    "     '--ignore', ignore_flake8, \n",
    "     '--import-order-style', 'edited',\n",
    "     '--count', \n",
    "     tmp_path],\n",
    "    stdout=subprocess.PIPE,\n",
    ").stdout.decode(\"ascii\")\n",
    "print(flake8_out)\n",
    "q_points -= int(flake8_out.splitlines()[-1])\n",
    "    \n",
    "print(\"\\u27A1 You received {} out of 5 points for subsetting the \"\n",
    "      \"streamflow data.\".format(\n",
    "    subset_points))\n",
    "\n",
    "subset_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d50ee6e2b5f04629e5694389a34eef37",
     "grade": false,
     "grade_id": "task-plot-subset",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "&#128187; Now, in the cell below, plot your subsetted data. Don't forget to label your plot!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f66eefd035a0cad068455450501375b",
     "grade": false,
     "grade_id": "ans-plot-subset",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c88f4825aeaf2d0a7246478a51c8d43a",
     "grade": false,
     "grade_id": "task-daily-plot",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You should be able to see the flood in your data going up above 1.88 million cfs at its peak in March 2019, as compared to the following year where the peak flow was 1.56 million cfs. But how unusual is that really?\n",
    "\n",
    "Let's start by plotting ALL the data. Then you can (optionally) use a return period **statistic** to quantify how unusual it was.\n",
    "\n",
    "&#128187; In the cell below, plot the entire time series of streamflow data, without any parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "203aa09940282bb04b9b273eeaa9079c",
     "grade": false,
     "grade_id": "ans-daily-plot",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "07c763f8c29eba9bc9faf4238cb34443",
     "grade": false,
     "grade_id": "instr-resample",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This plot looks a little fuzzy because it is trying to fit too many data points in a small area. One way to improve this is by **resampling** the data to **annual maxima**. That way we still get the same peak streamflows, but the computer will be able to plot all the values without overlapping.\n",
    "\n",
    "> **Resampling** means changing the time interval between time series observations - in this case from daily to annual.\n",
    "\n",
    "&#128214; Read about [different ways to resample time series data in your textbook](https://www.earthdatascience.org/courses/use-data-open-source-python/use-time-series-data-in-python/date-time-types-in-pandas-python/resample-time-series-data-pandas-python/)\n",
    "\n",
    "&#128214; You can use a [list of **offset aliases**](https://pandas.pydata.org/docs/dev/user_guide/timeseries.html#timeseries-offset-aliases) to look up how to specify the final dates. This list is pretty hard to find - you might want to bookmark it.\n",
    "\n",
    "&#128187; In the cell below, select the streamflow column, and then resample it to get an annual maximum.\n",
    "\n",
    "> GOTCHA ALERT - the test below is looking for a pandas `DataFrame`, but when we select a single column we get a pandas `Series` (a `DataFrame` is a collection of `Series` where each column is one `Series`.) To get a `DataFrame` with a single column, use the syntax below with **two** square brackets:\n",
    "\n",
    "```python\n",
    "dataframe[['column_name']]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c529e9bc45291695ef50b098237de18f",
     "grade": false,
     "grade_id": "ans-resample",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3be0b2aae4ff4a6c77266c503068cd59",
     "grade": true,
     "grade_id": "test-resample",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ans_resample = _\n",
    "resample_points = 0\n",
    "\n",
    "# Answer should be a DataFrame\n",
    "if isinstance(ans_resample, pd.DataFrame):\n",
    "    print(\"\\u2705 Great, you created a pandas DataFrame above\")\n",
    "    resample_points += 1\n",
    "else:\n",
    "    print(\"\\u274C Oops - the cell above should have a DataFrame output.\")\n",
    "\n",
    "# Answer should include 32 years of data\n",
    "if len(ans_resample)==32:\n",
    "    print(\"\\u2705 Your DataFrame has the right number of years\")\n",
    "    resample_points += 2\n",
    "else:\n",
    "    print(\"\\u274C Oops - did you resample your DataFrame to annual?\")\n",
    "\n",
    "# The mean of the streamflow Series should be 75378\n",
    "if round(int(ans_resample.mean().iloc[0]), 0)==75378:\n",
    "    print(\"\\u2705 Your annual max streamflow DataFrame has the expected \"\n",
    "          \"values in it, good job!\")\n",
    "    resample_points += 2\n",
    "else:\n",
    "    print(\"\\u274C Your annual max streamflow DataFrame does not have the \"\n",
    "          \"expected values in it.\")\n",
    "\n",
    "print(\"\\u27A1 You received {} out of 5 points for subsetting the \"\n",
    "      \"streamflow data.\".format(\n",
    "    resample_points))\n",
    "resample_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8dd8348d6bcaa5e094ad1b55a80bdff4",
     "grade": false,
     "grade_id": "instr-plot-annual",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "&#128187; Plot your resampled data.\n",
    "\n",
    "> HINT: use the rot=45 parameter to rotate the x-axis labels if you can't see them. You could also consider extracting the year only in your `DataFrame` before plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a733cd21a588f9be9a918b6c422a4d43",
     "grade": false,
     "grade_id": "discharge-monthly-max",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e25a268a2f33f6e83d0097c74c7f15ef",
     "grade": false,
     "grade_id": "task-describe",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "In the cell below, write a headline and 2-3 sentence description of your plot. What do you estimate the return period was for the flood in 2019?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WRITE YOUR HEADLINE HERE\n",
    "WRITE YOUR DESCRIPTION HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e9a7e0a2e70edc8a8efeca711657a15f",
     "grade": false,
     "grade_id": "peak-values",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> NOTE: You may be thinking...this really isn't enough years to get a good return period value, and you would be right! It turns out that the USGS also has **peak streamflow** values for years going back to the 1800s in Omaha. For your own analysis, one option would be to analyse the peak streamflow values instead, and/or compare them to the ones you computed in the years you have data. **GOTCHA ALERT** - the peak streamflow values from the USGS will be higher, because the daily data is a daily **average** rather than an instantaneous **maximum** like the peak flow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 6 (OPTIONAL): CALCULATE THE FLOOD RETURN PERIOD "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c0fe4d42446bea96ca206df0098344f",
     "grade": false,
     "grade_id": "task-return",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "&#127798; EXTRA CHALLENGE In the cell below, calculate the exceedence probability and return period for each year of the **annual** data, and add them as columns to your DataFrame.\n",
    "\n",
    "> HINT: pandas columns have a `rank` method, which you can use. BUT -- you will need to use the `ascending=False` parameter, since higher rank should be lower exceedence probability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d8cda4b09e90a30e7db8845f304752a",
     "grade": false,
     "grade_id": "ans-return",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1eccbf5bd046b26544390f2dd4120c90",
     "grade": true,
     "grade_id": "tests-return",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ans_return = _\n",
    "return_points = 0\n",
    "\n",
    "# Answer should be a DataFrame\n",
    "if isinstance(ans_return, pd.DataFrame):\n",
    "    print(\"\\u2705 Great, you created a pandas dataframe above\")\n",
    "    return_points += 1\n",
    "else:\n",
    "    print(\"\\u274C Oops - the cell above should have a DataFrame output.\")\n",
    "\n",
    "# Answer should include 32 years of data\n",
    "if len(ans_return)==32:\n",
    "    print(\"\\u2705 Your DataFrame has the right number of days\")\n",
    "    return_points += 2\n",
    "elif len(ans_return) > 32:\n",
    "    print(\"\\u274C Your DataFrame has too many years.\")\n",
    "else:\n",
    "    print(\"\\u274C Your DataFrame has too few years.\")\n",
    "\n",
    "# The value \"hash\" should be 20106.0\n",
    "if round(ans_return.mean().product(), 0)==157525.0:\n",
    "    print(\"\\u2705 Your streamflow DataFrame has the expected values \"\n",
    "          \"in it, good job!\")\n",
    "    return_points += 2\n",
    "else:\n",
    "    print(\"\\u274C Your streamflow DataFrame does not have the \"\n",
    "          \"expected values in it.\")\n",
    "    \n",
    "    # Subtract one point for any PEP-8 errors\n",
    "tmp_path = \"tmp.py\"\n",
    "with open(tmp_path, \"w\") as tmp_file:\n",
    "    tmp_file.write(In[-2])\n",
    "ignore_flake8 = 'W292,F401,E302,F821,W503'\n",
    "flake8_out = subprocess.run(\n",
    "    ['flake8', \n",
    "     '--ignore', ignore_flake8, \n",
    "     '--import-order-style', 'edited',\n",
    "     '--count', \n",
    "     tmp_path],\n",
    "    stdout=subprocess.PIPE,\n",
    ").stdout.decode(\"ascii\")\n",
    "print(flake8_out)\n",
    "return_points -= int(flake8_out.splitlines()[-1])\n",
    "\n",
    "print(\"\\u27A1 You received {} out of 5 extra credit points for calculating \"\n",
    "      \"return periods.\".format(return_points))\n",
    "return_points"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "248.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
